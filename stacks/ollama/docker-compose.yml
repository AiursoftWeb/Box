version: "3.6"

services:
  ollama_server:
    image: hub.aiursoft.cn/ollama/ollama:latest
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - ollama_net
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_KEEP_ALIVE=200m
      - OLLAMA_FLASH_ATTENTION=1
      - OLLAMA_KV_CACHE_TYPE=q8_0
      - GIN_MODE=release
    deploy:
      resources:
        limits:
          memory: 50G
        reservations:
          generic_resources:
            - discrete_resource_spec:
                kind: "NVIDIA-GPU"
                value: 0
      replicas: 1
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
      labels:
        swarmpit.service.deployment.autoredeploy: 'true'

  ollama_warmup:
    depends_on:
      - ollama_server
    image: hub.aiursoft.cn/alpine
    networks: 
      - ollama_net
    entrypoint:
      - "/bin/sh"
      - "-c"
      - |
          apk add curl && \
          sleep 40 && \
          while true; do \
            curl -v http://ollama_server:11434/api/generate -d '{"model": "deepseek-r1:70b"}'; \
            sleep 900; \
          done
    deploy:
      resources:
        limits:
          memory: 128M
      labels:
        swarmpit.service.deployment.autoredeploy: 'true'

networks:
  ollama_net:
    external: true

volumes:
  ollama-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /swarm-vol/ollama/data

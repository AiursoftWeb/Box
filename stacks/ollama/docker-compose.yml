version: "3.6"

services:
  ollama_starter:
    image: hub.aiursoft.cn/aiursoft/internalimages/ubuntu-with-docker:latest
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      # Kill existing ollama and then start a new ollama
    entrypoint: ["/bin/sh", "-c", "echo 'Starter is starting ollama...' && (docker kill ollama_server || true) && docker run --tty --rm --gpus=all -v /swarm-vol/ollama/data:/root/.ollama --network proxy_app --name ollama_server -e OLLAMA_HOST=0.0.0.0 -e OLLAMA_KEEP_ALIVE=200m -e OLLAMA_FLASH_ATTENTION=1 -e OLLAMA_KV_CACHE_TYPE=q8_0 -e GIN_MODE=release hub.aiursoft.cn/ollama/ollama:latest"]

  ollama_warmup:
    depends_on:
      - ollama_starter
    image: hub.aiursoft.cn/alpine
    networks: 
      - proxy_app
    entrypoint: ["/bin/sh", "-c", "apk add curl && sleep 20 && while true; do curl -v http://ollama_server:11434/api/generate -d '{\"model\": \"deepseek-r1:32b\"}'; sleep 900; done"]
    deploy:
      resources:
        limits:
          memory: 128M
      labels:
        swarmpit.service.deployment.autoredeploy: 'true'

networks:
  proxy_app:
    external: true

volumes:
  ollama-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /swarm-vol/ollama/data

############################################
# 1) Source: 从 Caddy 日志文件读取，每行都是 JSON
[sources.caddy]
type = "file"
include = ["/data/caddy/logs/web.log"]
fingerprint.strategy = "device_and_inode"

############################################
# 2) Transform: Remap Language 解析 JSON，抽取所有字段
[transforms.parse]
type   = "remap"
inputs = ["caddy"]
source = '''
structured = parse_json!(.message)

. = {
  "ts":           structured.ts,
  "level":        structured.level,
  "logger":       structured.logger,
  "msg":          structured.msg,
  "remote_ip":    structured.request.remote_ip,
  "remote_port":  to_int!(structured.request.remote_port),
  "method":       structured.request.method,
  "host":         structured.request.host,
  "uri":          structured.request.uri,
  "status":       to_int!(structured.status),
  "duration_ms":  to_float!(structured.duration) * 1000.0,
  "bytes_sent":   to_int!(structured.size),
  "user_agent":   to_string!(structured.request.headers."User-Agent"[0]),
  "err_id":       to_string!(structured.err_id),
  "err_trace":    to_string!(structured.err_trace)
}

del(.message)
'''

############################################
# 2a) Filter: 只保留真正的 HTTP access 日志
[transforms.filter_access]
type      = "filter"
inputs    = ["parse"]
condition = '.logger == "http.log.access"'

############################################
# 3) Sink: 写入 ClickHouse，只消费 filter_access 输出
[sinks.clickhouse]
type               = "clickhouse"
inputs             = ["filter_access"]
endpoint           = "http://clickhouse:8123"
compression        = "gzip"
database           = "logs"
table              = "caddy_requests"
auth.strategy      = "basic"
auth.user          = "default"
auth.password      = "123456"
skip_unknown_fields = true
batch.max_events   = 1000

# 可选子表配置
[sinks.clickhouse.request]
timeout_secs = 30
